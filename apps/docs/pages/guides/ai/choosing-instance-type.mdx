import Layout from '~/layouts/DefaultGuideLayout'
import { Tabs } from 'ui'
export const TabPanel = Tabs.Panel

export const meta = {
  id: 'ai-choosing-instance-type',
  title: 'Choosing Compute Add-on',
  description: 'Choosing the right Compute Add-on for your workload.',
  subtitle: 'Choosing the right Compute Add-on for your workload.',
  sidebar_label: 'Choosing Compute Add-on',
}

This guide will help you choose the right Compute Add-on for your workload. We'll provide general guidance, as it is impossible to provide specific instructions for every possible use case. The goal is to give you a starting point from which you can make your own benchmarks and optimizations.

For more information about engineering at scale, see our [Engineering for Scale](/docs/guides/ai/engineering-for-scale) guide.

## Simple workloads

We've run a set of benchmarks using the [gist-960-angular](http://corpus-texmex.irisa.fr/) dataset. This dataset contains 1,000,000 embeddings for images, with each embedding being 960 dimensions. And using the [GloVe Reddit comments](https://nlp.stanford.edu/projects/glove/) dataset, which contains 1,623,397 embeddings for words, with each embedding being 512 dimensions.

We used [Vecs](https://github.com/supabase/vecs) to create a collection, upload the embeddings to a single table, and create an `inner-product` index for the embedding column. We then ran a series of queries to measure the performance of different compute add-ons:

### Results

<Tabs
  scrollable
  size="small"
  type="underlined"
  defaultActiveId="gist960"
>
<TabPanel id="gist960" label="gist-960, probes = 10">

Emdeddings of 960 dimensions from gist-960 dataset with 1,000,000 vectors.

| Plan   | Vectors   | Lists | RPS  | Latency Mean | Latency p95 | RAM Usage          | RAM    |
| ------ | --------- | ----- | ---- | ------------ | ----------- | ------------------ | ------ |
| Free   | 30,000    | 30    | 75   | 0.065 sec    | 0.088 sec   | 1 GB + 100 Mb Swap | 1 GB   |
| Small  | 100,000   | 100   | 78   | 0.064 sec    | 0.092 sec   | 1.8 GB             | 2 GB   |
| Medium | 250,000   | 250   | 58   | 0.085 sec    | 0.129 sec   | 3.2 GB             | 4 GB   |
| Large  | 500,000   | 500   | 55   | 0.088 sec    | 0.140 sec   | 5 GB               | 8 GB   |
| XL     | 1,000,000 | 1000  | 110  | 0.046 sec    | 0.070 sec   | 14 GB              | 16 GB  |
| 2XL    | 1,000,000 | 1000  | 235  | 0.083 sec    | 0.136 sec   | 10 GB              | 32 GB  |
| 4XL    | 1,000,000 | 1000  | 420  | 0.071 sec    | 0.106 sec   | 11 GB              | 64 GB  |
| 8XL    | 1,000,000 | 1000  | 815  | 0.072 sec    | 0.106 sec   | 13 GB              | 128 GB |
| 12XL   | 1,000,000 | 1000  | 1150 | 0.052 sec    | 0.078 sec   | 15.5 GB            | 192 GB |
| 16XL   | 1,000,000 | 1000  | 1345 | 0.072 sec    | 0.106 sec   | 17.5 GB            | 256 GB |

</TabPanel>
<TabPanel id="glove512" label="GloVe-512, probes = 10">

Emdeddings of 512 dimensions from GloVe Reddit comments dataset with 1,623,397 vectors.

| Plan   | Vectors   | Lists | RPS  | Latency Mean | Latency p95 | RAM Usage          | RAM    |
| ------ | --------- | ----- | ---- | ------------ | ----------- | ------------------ | ------ |
| Free   | 100,000   | 100   | 250  | 0.395 sec    | 0.432 sec   | 1 GB + 300 Mb Swap | 1 GB   |
| Small  | 250,000   | 250   | 440  | 0.223 sec    | 0.250 sec   | 2 GB + 200 Mb Swap | 2 GB   |
| Medium | 500,000   | 500   | 425  | 0.116 sec    | 0.143 sec   | 3.7 GB             | 4 GB   |
| Large  | 1,000,000 | 1000  | 515  | 0.096 sec    | 0.116 sec   | 7.5 GB             | 8 GB   |
| XL     | 1,623,397 | 1275  | 465  | 0.212 sec    | 0.272 sec   | 14 GB              | 16 GB  |
| 2XL    | 1,623,397 | 1275  | 1400 | 0.061 sec    | 0.075 sec   | 22 GB              | 32 GB  |
| 4XL    | 1,623,397 | 1275  | 1800 | 0.027 sec    | 0.043 sec   | 20 GB              | 64 GB  |
| 8XL    | 1,623,397 | 1275  | 2850 | 0.032 sec    | 0.049 sec   | 21 GB              | 128 GB |
| 12XL   | 1,623,397 | 1275  | 3700 | 0.020 sec    | 0.036 sec   | 26 GB              | 192 GB |
| 16XL   | 1,623,397 | 1275  | 3700 | 0.025 sec    | 0.042 sec   | 29 GB              | 256 GB |

Random vectors were generated for queries.

</TabPanel>
<TabPanel id="glove512_60" label="GloVe-512, probes = 60">

Emdeddings of 512 dimensions from GloVe Reddit comments dataset with 1,623,397 vectors.

| Plan   | Vectors   | Lists | RPS | Latency Mean | Latency p95 | RAM Usage | RAM    |
| ------ | --------- | ----- | --- | ------------ | ----------- | --------- | ------ |
| Free   | 100,000   | 100   | -   | -            | -           | -         | 1 GB   |
| Small  | 250,000   | 250   | -   | -            | -           | -         | 2 GB   |
| Medium | 500,000   | 500   | 75  | 0.656 sec    | 0.750 sec   | 3.7 GB    | 4 GB   |
| Large  | 1,000,000 | 1000  | 102 | 0.488 sec    | 0.580 sec   | 7.5 GB    | 8 GB   |
| XL     | 1,000,000 | 1000  | 188 | 0.525 sec    | 0.596 sec   | 14 GB     | 16 GB  |
| XL     | 1,623,397 | 1275  | 75  | 0.679 sec    | 0.798 sec   | 14 GB     | 16 GB  |
| 2XL    | 1,623,397 | 1275  | 160 | 0.314 sec    | 0.384 sec   | 22 GB     | 32 GB  |
| 4XL    | 1,623,397 | 1275  | 300 | 0.083 sec    | 0.113 sec   | 20 GB     | 64 GB  |
| 8XL    | 1,623,397 | 1275  | 565 | 0.105 sec    | 0.141 sec   | 21 GB     | 128 GB |
| 12XL   | 1,623,397 | 1275  | 840 | 0.093 sec    | 0.124 sec   | 26 GB     | 192 GB |
| 16XL   | 1,623,397 | 1275  | 940 | 0.084 sec    | 0.108 sec   | 29 GB     | 256 GB |

Random vectors were generated for queries.

</TabPanel>
</Tabs>

<Admonition type="note">

It is possible to upload more vectors to a single table if Memory allows it (for example, 2XL plan and higher). But it will affect the performance of the queries: RPS will be lower, and latency will be higher. Scaling should be almost linear, but it is recommended to benchmark your workload to find the optimal number of vectors per table and per database instance.

</Admonition>

## Methodology

We follow techniques outlined in the [ANN Benchmarks](https://github.com/erikbern/ann-benchmarks) methodology. A Python test runner is responsible for uploading the data, creating the index, and running the queries. The pgvector engine is implemented using [vecs](https://github.com/supabase/vecs), a Python client for pgvector.

<div>
  <img
    alt="multi database"
    className="dark:hidden"
    src="/docs/img/ai/instance-type/vecs-benchmark--light.png"
  />
  <img
    alt="multi database"
    className="hidden dark:block"
    src="/docs/img/ai/instance-type/vecs-benchmark--dark.png"
  />
</div>

Each test is run for a minimum of 30-40 minutes. They include a series of experiments executed at different concurrency levels to measure the engine's performance under different load types. The results are then averaged.

As a general recommendation, we suggest using a concurrency level of 5 or more for most workloads and 30 or more for high-load workloads.

## Future benchmarks

We'll continue to add more benchmarks on datasets consisting of different vector dimensions, number of `lists` in the index, and number of `probes` in the index. Stay tuned for more information about how it may affect the performance and precision of your queries.

export const Page = ({ children }) => <Layout meta={meta} children={children} />

export default Page
