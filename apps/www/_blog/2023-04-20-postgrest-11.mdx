---
title: 'PostgREST v11: configurable role settings, isolation level and more'
description: 'PostgREST v11 new features'
author: steve_chavez
image: lw6-community/postgrest.png
thumb: lw6-community/postgrest.png
tags:
  - postgres
  - rest
  - isolation level
  - transactions
  - roles
  - planetpg
date: '2023-04-20'
toc_depth: 3
---

PostgREST 11 was just released. In addition to the [pre-release](https://supabase.com/blog/postgrest-11-prerelease) features, we’ve added security, configuration and querying improvements.

## Configurable Role Settings

Role settings are now applied on every request, you can set these with a regular `ALTER ROLE <role> SET <setting>`. This is useful, for example, to prevent web users from running expensive queries.

Let’s try it by setting a statement timeout and cost limit.

### Statement timeout

`statement_timeout` aborts any statement that takes more than the specified amount of time. Let’s set it for the usual `anon`, `authenticated` and `service_role` roles:

```sql
-- anon users can only run queries that take 100 milliseconds max
alter role anon set statement_timeout = '100ms';

-- authenticated users can only run queries that take 5 seconds max
alter role authenticated set statement_timeout = '5s';

-- service_role users can only run queries that take 15 seconds max
alter role service_role set statement_timeout = '15s';
```

You need to reload PostgREST config cache to apply these changes.

```sql
NOTIFY pgrst, 'reload config';
```

Now, suppose you have a big table and you apply a filter on an unindexed column:

```jsx
const { data, error } = await supabase
  .from('big_table')
  .select()
  .eq('unindexed_column', 'value')
```

Then, after 5 seconds, the request will be aborted and the response will be:

```json
{
  "hint": null,
  "details": null,
  "code": "57014",
  "message": "canceling statement due to statement timeout"
}
```

### Statement cost limit

With `statement_timeout`, queries will still run for that length of time, consuming resources until they’re terminated. To prevent this, you can abort queries based on their plan cost — this is determined at the planning phase, before they get executed.

```sql
-- anon users can only run cheap queries
ALTER USER anon SET plan_filter.statement_cost_limit = 10000;

-- authenticated users can run more expensive queries
ALTER USER authenticated SET plan_filter.statement_cost_limit = 1e6;

-- service_role can run any query
ALTER USER service_role SET plan_filter.statement_cost_limit = 0;

NOTIFY pgrst, 'reload config'; -- reload postgREST config cache to apply changes
```

Let’s repeat the previous example.

```jsx
const { data, error } = await supabase
  .from('big_table')
  .select()
  .eq('unindexed_column', 'value')
```

Then, immediately, the request will be aborted and the response will be:

```jsx
{
  "hint": null,
  "details": null,
  "code": "54001",
  "message": "plan cost limit exceeded"
}
```

This uses the [pg_plan_filter](https://github.com/pgexperts/pg_plan_filter) extension(available on the Supabase platform) and requires tuning to get the cost limit right. You should use this with care as it can invalidate legitimate queries.

## Configurable transaction isolation level

By default, all queries in PostgREST run in a transaction with the default *Read Committed* isolation level.

```sql
BEGIN ISOLATION LEVEL READ COMMITTED;
-- <query>
COMMIT;
```

Now you can change this by settting `default_transaction_isolation`.

You can do it per-function:

```sql
create function hello()
returns text as $$
  select 'hello';
$$ language sql
set default_transaction_isolation = 'repeatable read';
```

Or per-role, which will affect all queries ran by that role:

```sql
alter role service_role set default_transaction_isolation = 'serializable';
NOTIFY pgrst, 'reload config'; -- reload postgREST config cache
```

Trying out the function above.

```jsx
const { data, error } = await supabase
  .rpc('hello')
```

Will result in PostgREST running the query with the *Repeatable Read* isolation level:

```sql
BEGIN ISOLATION LEVEL REPEATABLE READ;
-- SELECT hello();
COMMIT;
```

Note that the default *Read Committed* is good enough for almost all use cases. Using higher isolation levels will incur in overhead as they use more sophisticated locking.

## Bulk insert JSON with default values

A long wanted feature was bulk inserting JSON while considering columns' default values.

Having the following sample table.

```sql
create table foo
( id bigint generated by default as identity primary key
, bar text
, baz int default 100
);
```

You can now do it like this:

```jsx
const { error } = await supabase
  .from('foo')
  .insert([
	  { "bar": "val1"
	  }
	, { "bar": "val2"
	  , "baz": 15
	  }
	], defaultToNull: false)
  .select()
```

And the respone will be:

```json
[
  { "id":  1
  , "bar": "val1"
  , "baz": 100
  }
, { "id":  2
  , "bar": "val2"
  , "baz": 15
  }
]
```

As you can see, `id` and `baz` took their default values.

## ANY/ALL filter modifiers

As a shortcut to `OR` filters, you can now use `any` modifiers on various filters. Take the `like` filter as an example:

```jsx
const res = await postgrest
    .from('users')
    .select()
    .likeAnyOf('username', ['%supa%', '%kiwi%'])
```

This is equivalent to the following in SQL.

```sql
SELECT * FROM users WHERE username LIKE ANY('{%supa%,%kiwi%}');
```

`any` modifiers are available for the `eq,like,ilike,gt,gte,lt,lte,match,imatch` filters.

For completeness, the `all` modifier is also added.

## Closing up

There you have it, now you can make your API more secure with role settings and use higher isolation levels without resorting to direct PostgreSQL connections.

PostgREST v11 is being rolled on the Supabase platform, it will be available for new projects on the coming week.
