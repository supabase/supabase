---
id: logs
title: Logging
description: Getting started with Supabase Platform Log Browser
---

The Supabase Platform provides a log explorer that allows log tracing and debugging. Currently, PostgreSQL and Cloudflare edge logs are available.

:::note

The features discussed in this article are only available through the Supabase Platform and are not available on self-hosted. 

:::

## Product Logs

As well as a Log Explorer, Supabase provides a logging interface specific to each product.

### API Logs 

![API Logs](/img/guides/platform/logs/logs-api.png)

The API Logs can be found under `Database > API Logs`. These show all network requests for the REST and GraphQL [API](/docs/guides/api).

### Postgres Logs

![Postgres Logs](/img/guides/platform/logs/logs-database.png)

The Postgres Logs can be found under `Database > Postgres Logs`. These show all queries and activity for your [Database](/docs/guides/database).


## Log Explorer

![Sidebar navigation steps](/img/guides/platform/logs/sidebar-navigation.png)

The log browser can be accessed in the sidebar under **Logs Explorer**. The **Logs Explorer** is for querying and aggregating project logs across products using SQL `SELECT` queries.


### Example
For example, you may enter the following into the SQL editor to query for each user's IP address:

```sql
SELECT timestamp, h.x_real_ip
FROM edge_logs
  LEFT JOIN UNNEST(metadata) as m ON TRUE
  LEFT JOIN UNNEST(m.request) AS r ON TRUE
  LEFT JOIN UNNEST(r.headers) AS h ON TRUE
WHERE h.x_real_ip IS NOT NULL
```

![SELECT query example](/img/guides/platform/logs/select-query.png)


The log source, `edge_logs`, is required in order to formulate the SELECT query. Likewise, when querying the database logs, you would need to provide a table name reference as well. The list of supported product sources can be found under the **Sources** dropdown.

Cross-source joining is currently supported.

### Unnesting Arrays

In the above example, in order to query across the metadata field, we need to unnest the field and add it as a join. When we inspect on an individual log by clicking on the log row, we can see that log metadata is stored as an array of objects. 

In order to query any value that is an array, we would need to `UNNEST()` that field and add it to the query as a join, thereby allowing us to reference the nested fields within the array.


### Functions

You may have also noticed from the above examples that we are able to use certain SQL functions within our queries. The querying engine currently supported is BigQuery, hence you may use [any valid BigQuery function](https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators) within your query. 


#### Timestamp Behavior

Each log timestamp is stored as a `TIMESTAMP` data type. In order to utilize the `timestamp` field in a query, you would need to use the appropriate [timestamp function](https://cloud.google.com/bigquery/docs/reference/standard-sql/timestamp_functions#timestamp) to query across the timestamp field.

:::note

Although timestamps are rendered as unix microsecond timestamps in the Log Explorer, SQL queries should use the `TIMESTAMP` data type only. If using a unix timestamp value in a query, cast the value to a `TIMESTAMP` data type.

:::

## Templates

Templates are available to help shorten the time needed to craft these queries. There are examples for each complexity level, which can serve as a foundation for your custom queries. Templates are available under the **Templates** tab, or under the **Templates** Dropdown in the **Query** tab.
